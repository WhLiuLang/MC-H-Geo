# -*- coding: utf-8 -*-
"""
æœ€ç»ˆå®éªŒè„šæœ¬: ä¸¤æ­¥èµ°åœ°è´¨åå¤„ç† (Zè½´åˆ†å±‚ + å±€éƒ¨å¹³æ»‘)

åŠŸèƒ½:
1.  ã€ç¬¬ä¸€æ­¥ - å®è§‚ä¿®æ­£ã€‘æ‰§è¡ŒZè½´åœ°å±‚æ‰«æä¸ç½®ä¿¡åº¦åŠ æƒæ™ºèƒ½ä¿®æ­£ï¼Œå»ºç«‹åœ°å±‚ä¸»ä½“æ¡†æ¶ã€‚
2.  ã€ç¬¬äºŒæ­¥ - ä»‹è§‚å¹³æ»‘ã€‘åœ¨å®è§‚ä¿®æ­£ç»“æœçš„åŸºç¡€ä¸Šï¼Œå†æ‰§è¡Œä¸€æ¬¡åŸºäºå±€éƒ¨é‚»åŸŸçš„ç½®ä¿¡åº¦åŠ æƒå¹³æ»‘ï¼Œ
    å¯¹å²©æ€§è¾¹ç•Œå’Œç»†èŠ‚è¿›è¡Œæœ€ç»ˆçš„â€œæ‰“ç£¨â€ã€‚
3.  è¯„ä¼°æ¯ä¸€æ­¥å¤„ç†å¸¦æ¥çš„æ€§èƒ½å˜åŒ–ã€‚
"""
import pandas as pd
import numpy as np
from collections import Counter
from tqdm import tqdm
import os
from sklearn.metrics import accuracy_score, f1_score
from scipy.spatial import cKDTree

# ======================= 1. ç”¨æˆ·é…ç½®åŒº =======================
# --- è¾“å…¥è·¯å¾„ ---
# è¯·ç¡®ä¿è¿™ä¸ªé¢„æµ‹æ–‡ä»¶åŒ…å« 'filename', 'predicted_label', 'confidence' ä¸‰åˆ—
PREDICTIONS_CSV = "path"
CENTROIDS_CSV = "path"
GROUND_TRUTH_CSV = "path"

# --- è¾“å‡ºè·¯å¾„ ---
OUTPUT_DIR = "final_postprocessing_files"
OUTPUT_SMOOTHED_CSV = os.path.join(OUTPUT_DIR, "final_two_step_smoothed_predictions.csv")

# --- ç®—æ³•å‚æ•° ---
VEGETATION_LABEL = 3
# --- é˜¶æ®µä¸€ï¼šZè½´åˆ†å±‚å‚æ•° ---
SWEEP_STEP = 0.1
LAYER_TOLERANCE = 0.05
# --- é˜¶æ®µäºŒï¼šå±€éƒ¨å¹³æ»‘å‚æ•° ---
LOCAL_SMOOTHING_RADIUS = 0.5 


# ======================= 2. ä¸»æ‰§è¡Œæµç¨‹ =======================
def main():
    print("--- ç»ˆæä¸¤æ­¥èµ°åå¤„ç†è„šæœ¬å¯åŠ¨ ---")
    os.makedirs(OUTPUT_DIR, exist_ok=True)

    # --- æ­¥éª¤ 1: åŠ è½½æ‰€æœ‰å¿…éœ€æ–‡ä»¶ ---
    print("æ­¥éª¤ 1: åŠ è½½é¢„æµ‹ã€åæ ‡å’ŒçœŸå®æ ‡ç­¾...")
    try:
        df_preds = pd.read_csv(PREDICTIONS_CSV, encoding='utf-8-sig')
        df_centroids = pd.read_csv(CENTROIDS_CSV, encoding='utf-8-sig')
        df_truth = pd.read_csv(GROUND_TRUTH_CSV, usecols=['filename', 'label'], encoding='gbk')
        df_truth['label'] = np.where(df_truth['label'] == 4, 0, df_truth['label'])
    except Exception as e:
        print(f"é”™è¯¯: è¯»å–æ–‡ä»¶æ—¶å‡ºé”™ã€‚ {e}"); return

    if 'confidence' not in df_preds.columns:
        print("é”™è¯¯: è¾“å…¥çš„é¢„æµ‹æ–‡ä»¶ PREDICTIONS_CSV ä¸­ç¼ºå°‘ 'confidence' åˆ—ï¼");
        return

    df_full = pd.merge(df_centroids, df_preds, on='filename')
    print(f"æ•°æ®åŠ è½½æˆåŠŸï¼Œæ€»è®¡ {len(df_full)} ä¸ªä½“ç´ ã€‚")

    # ======================= é˜¶æ®µä¸€ï¼šZè½´åœ°å±‚æ‰«æå®è§‚ä¿®æ­£ =======================
    print("\n--- é˜¶æ®µä¸€ï¼šæ‰§è¡ŒZè½´åœ°å±‚æ‰«æå®è§‚ä¿®æ­£ ---")

    # åˆå§‹åŒ–ä¸€ä¸ªæ–°åˆ—æ¥å­˜å‚¨ç¬¬ä¸€æ­¥ä¿®æ­£çš„ç»“æœ
    df_full['strata_smoothed_label'] = df_full['predicted_label']
    min_z, max_z = df_full['z'].min(), df_full['z'].max()

    height_range = np.arange(max_z, min_z, -SWEEP_STEP)
    for z_height in tqdm(height_range, desc="Phase 1: Strata Sweeping"):
        layer_mask = df_full['z'].between(z_height - LAYER_TOLERANCE, z_height + LAYER_TOLERANCE)
        layer_df = df_full[layer_mask]
        if len(layer_df) < 2: continue

        votes = layer_df.groupby('predicted_label')['confidence'].sum()
        rock_votes = votes.drop(VEGETATION_LABEL, errors='ignore')

        if not rock_votes.empty:
            dominant_lithology = rock_votes.idxmax()
            correction_mask = (layer_df['predicted_label'] != dominant_lithology) & (
                        layer_df['predicted_label'] != VEGETATION_LABEL)
            indices_to_correct = layer_df[correction_mask].index
            df_full.loc[indices_to_correct, 'strata_smoothed_label'] = dominant_lithology

    # ======================= é˜¶æ®µäºŒï¼šå±€éƒ¨é‚»åŸŸå¹³æ»‘â€œæ‰“ç£¨â€ =======================
    print("\n--- é˜¶æ®µäºŒï¼šæ‰§è¡Œå±€éƒ¨é‚»åŸŸå¹³æ»‘â€œæ‰“ç£¨â€ ---")

    # æ„å»ºç©ºé—´ç´¢å¼•
    coordinates = df_full[['x', 'y', 'z']].values
    kdtree = cKDTree(coordinates)

    # æ‰¾åˆ°æ¯ä¸ªç‚¹çš„ç©ºé—´é‚»å±…
    neighbor_indices_list = kdtree.query_ball_tree(kdtree, r=LOCAL_SMOOTHING_RADIUS)

    # åˆå§‹åŒ–æœ€ç»ˆæ ‡ç­¾åˆ—
    final_labels = []

    # åœ¨ç¬¬ä¸€æ­¥ä¿®æ­£ç»“æœçš„åŸºç¡€ä¸Šè¿›è¡ŒæŠ•ç¥¨
    for i in tqdm(range(len(df_full)), desc="Phase 2: Local Smoothing"):
        neighbor_indices = neighbor_indices_list[i]

        # æŠ•ç¥¨çš„â€œé€‰ç¥¨â€æ¥è‡ªäºç¬¬ä¸€é˜¶æ®µä¿®æ­£åçš„æ ‡ç­¾
        neighbor_labels = df_full.iloc[neighbor_indices]['strata_smoothed_label'].values

        if len(neighbor_labels) > 0:
            most_common_label = Counter(neighbor_labels).most_common(1)[0][0]
            final_labels.append(most_common_label)
        else:
            # å¦‚æœæ²¡æœ‰é‚»å±…ï¼Œåˆ™ä¿ç•™ç¬¬ä¸€é˜¶æ®µçš„ç»“æœ
            final_labels.append(df_full.iloc[i]['strata_smoothed_label'])

    df_full['final_smoothed_label'] = final_labels

    # ======================= è¯„ä¼°ä¸ä¿å­˜ =======================
    print("\n--- æœ€ç»ˆæ€§èƒ½è¯„ä¼° ---")
    df_eval = pd.merge(df_full, df_truth, on='filename', how='inner')
    if not df_eval.empty:
        y_true = df_eval['label'].values
        y_pred_before = df_eval['predicted_label'].values
        y_pred_strata = df_eval['strata_smoothed_label'].values
        y_pred_final = df_eval['final_smoothed_label'].values

        acc_before = accuracy_score(y_true, y_pred_before)
        acc_strata = accuracy_score(y_true, y_pred_strata)
        acc_final = accuracy_score(y_true, y_pred_final)

        print("\n--- æ€§èƒ½å¯¹æ¯” ---")
        print(f"åˆæ­¥é¢„æµ‹ - å‡†ç¡®ç‡ (Accuracy): {acc_before:.4f}")
        print(f"é˜¶æ®µä¸€å - å‡†ç¡®ç‡ (Accuracy): {acc_strata:.4f}")
        print(f"é˜¶æ®µäºŒå - å‡†ç¡®ç‡ (Accuracy): {acc_final:.4f}")

        gain_1 = acc_strata - acc_before
        gain_2 = acc_final - acc_strata
        total_gain = acc_final - acc_before
        print(f"\n>>> é˜¶æ®µä¸€æå‡: {gain_1:+.4f}")
        print(f">>> é˜¶æ®µäºŒæå‡: {gain_2:+.4f}")
        if acc_before > 0: print(f">>> æ€»æå‡: {total_gain:+.4f} ({(total_gain / acc_before):+.2%})")

    df_full.to_csv(OUTPUT_SMOOTHED_CSV, index=False, encoding='utf-8-sig')
    print(f"\nğŸ‰ğŸ‰ğŸ‰ æœ€ç»ˆä¸¤æ­¥èµ°å¹³æ»‘ç»“æœå·²ä¿å­˜è‡³: {OUTPUT_SMOOTHED_CSV} ğŸ‰ğŸ‰ğŸ‰")


if __name__ == "__main__":
    main()